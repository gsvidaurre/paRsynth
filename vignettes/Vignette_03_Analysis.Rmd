---
title: "Vignette_03_Analysis"
author: "GAJ"
date: "2024-12-11"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

<h2>How to Analyze paRsynth Outputs</h2>

In this vignette, we will go through how to analyze the synthetic vocalization generated by the paRsynth package for downstream bioacoustics analysis by creating spectrograms and creating acoustic plots to compare bioacoustic similarity of the paRsynth generated vocalizations from Vignette 02.

**Preliminary Steps**

Before analyzing the outputs you generated with paRsynth, there are some preliminary steps we must go through to ensure it will work appropriately and organized neatly.

<u>Step i. Re-load packages and reset paths</u>

```{r message = FALSE, warning = FALSE}

# Clean the global environment
rm(list = ls())

# Specify the required packages
X <- c("devtools", "dplyr", "stringdist", "tidyverse", "ggplot2", "apcluster", "soundgen", "parallel", "stringr", "data.table", "tuneR", "pbapply", "warbleR", "magrittr")

# Install the packages in X if not already installed
is_installed <- function(p) is.element(p, installed.packages()[,1])

invisible(lapply(1:length(X), function(x){
  if(!is_installed(X[x])){
    install.packages(X[x], repos = "http://lib.stat.cmu.edu/R/CRAN")
  }
}))

# Install the paRsynth package from GitHub if you haven't installed it already
# devtools::install_github("gsvidaurre/paRsynth")

# Add paRsynth to the list of packages to load
# X <- c(X, "paRsynth")

# Change "Desktop/.../GitHub_repos" based on where paRsynth is stored on your local machine
testing_path <- "~/Desktop/BIRDS/GitHub_repos/paRsynth/R"

# Load the paRsynth functions that will be tested below
source(file.path(testing_path, "generate_strings.R"))
source(file.path(testing_path, "parsons_code.R"))
source(file.path(testing_path, "frequency_anchors.R"))
source(file.path(testing_path, "write_audio.R"))

# Load all of the packages specified above
invisible(lapply(X, library, character.only = TRUE))

```

<u> Step ii. Re-initialize working directories for data on your local machine </u>

It is important to have your files organized especially when creating many different types of output data. Therefore, initializing working directories througout will be helpful analyzing the data you create with paRsynth.

```{r eval = TRUE}

# Initialize a base path (this will need to be different per user)
# path <- "/Users/raneemsamman/Desktop" # Raneem's path
# path <- "/Users/gracesmith-vidaurre/Desktop" # Grace's path
path <- "/Users/gretheljuarez/Desktop/BIRDS/paRsynth_Data" # Alexandra's path

# Initialize the directory for analysis on your local computer
analysis_dir <- "paRsynth_methods_synthetic_dataset"

# Combine the base path and the data directory into a single path
analysis_path <- file.path(path, analysis_dir)

# Create the data directory if it doesn't already exist on your computer
if(!dir.exists(analysis_path)){ 
  dir.create(analysis_path)
}

# Specify a folder inside the analysis directory where audio will be written out/read in
audio_dir <- "audio"

# Combine the base path, the analysis directory, and the audio directory into a single path
audio_path <- file.path(path, analysis_dir, audio_dir)

# Create the audio directory if it doesn't already exist on your computer
if(!dir.exists(audio_path)){ 
  dir.create(audio_path)
}

# Specify a folder inside the analysis directory where images will be written out/read in
images_dir <- "images"

# Combine the base path, the analysis directory, and the data directory into a single path
images_path <- file.path(path, analysis_dir, images_dir)

# Create the data directory if it doesn't already exist on your computer
if(!dir.exists(images_path)){ 
  dir.create(images_path)
}

```

**Bioacoustic Analysis Steps**

<u> Step 1: Create a warbleR selection table </u>

To organize all the paRsynth generated outputs you created in the previous vignettes, you will have to create a warbleR selection table. This package is very useful to streamline bioacustic analysis. First you will list all the .wav files then organize them in a selection table.

```{r message = FALSE, warning = FALSE}

# Create a vector of all of the audio files in the analysis path
wavs <- list.files(path = audio_path, pattern = ".wav$", full.names = FALSE)
length(wavs)
head(wavs)
tail(wavs)

# w <- 25 # testing

sel_tbl <- data.table::rbindlist(lapply(1:length(wavs), function(w){
  
  tmp <- tuneR::readWave(file.path(audio_path, wavs[w]))
  
  # Return the metadata for the given call using the synthetic metadata generated during audio file generation above
  
  synthetic_call_metadata <- read.csv("~/Desktop/BIRDS/paRsynth_Data/paRsynth_methods_synthetic_dataset/synthetic_call_metadata.csv")
  
  metadats_tmp <- synthetic_call_metadata %>%
    dplyr::filter(grepl(wavs[w], audio_file_name))
  
  # glimpse(metadats_tmp)
  
  # Create a row for the selection table in warbleR format if the audio file exists and metadata for that file also exists
  if(nrow(metadats_tmp) > 0){
    
    # Use 0.1s as a margin to indicate where the vocalization starts and ends in the audio file
    # soundgen::soundgen() adds 100ms of silence before and after the synthetic vocalization by default 
    res <- data.frame(
      sound.files = wavs[w], 
      selec = 1,
      start = 0.1, 
      end = seewave::duration(tmp) - 0.1,
      sampling_rate = tmp@samp.rate,
      group_ID = metadats_tmp[["Group"]],
      individual_ID = metadats_tmp[["Individual"]],
      call_ID = metadats_tmp[["Call"]]
    )
    
  } else {
    
    res <- data.frame(
      sound.files = wavs[w], 
      selec = 1, 
      start = 0.1, 
      end = seewave::duration(tmp) + 0.1,
      sampling_rate = NA,
      group_ID = NA,
      individual_ID = NA,
      call_ID = NA
    )
    
  }
  
  return(res)
  
}))

# See the selection table in warbleR format with all useful metadata for the synthetic experiment
# View(sel_tbl)
glimpse(sel_tbl)

unique(sel_tbl$sampling_rate)

```

This will output a neatly organized selection table of the unique generated vocalizations.

<u> Step 2: Create spectrogram image files of each audio file </u>

Using the warbleR package, spectrogram images can be created from each synthetic vocalization you generated with paRsynth. Using a spectrogram is beneficial to analyze vocalizations because it provides precise information on frequency over time. First, you will use warbleR to create spectrograms of the generated vocalization in the selection table. Then you will rename the spectrograms image files save in your images_path.

```{r message = FALSE, warning = FALSE}

# To make spectrograms of dataset 1 (more group info), you will need to filter it out from the selection table you made above.
GroupMembership_sel_tbl <- sel_tbl %>%
    dplyr::filter(grepl("GroupMembership", sound.files))

# View(GroupMembership_sel_tbl)
glimpse(GroupMembership_sel_tbl)

warbleR::spectrograms(GroupMembership_sel_tbl, wl = 512, flim = c(0, 12), wn = "hanning", pal = reverse.gray.colors.2,ovlp = 90, inner.mar = c(5, 4, 4, 2), outer.mar = c(0, 0, 0, 0), picsize = 1, res = 100, cexlab = 1, propwidth = FALSE, xl = 1, osci = FALSE, gr = FALSE, sc = FALSE, line = FALSE, mar = 0.05, it = "jpeg", parallel = 1, path = audio_path, pb = TRUE, fast.spec = FALSE, by.song = NULL, sel.labels = NULL, title.labels = NULL, dest.path = images_path, box = TRUE, axis = TRUE)

# Rename the image files
imgs <- list.files(images_path)
imgs

new_nms <- gsub(".wav-1", "", imgs)
new_nms

invisible(file.rename(file.path(images_path, imgs), file.path(images_path, new_nms)))

```

This will output appropriately named spectrograms for the generated vocalizations in the selection table created previously. 

<u> Step 3: Perform spectrogrphic cross-correlation (SPCC) to measure acoustic similarity of all calls in dataset (pairwise similarity matrix) </u>

Now, we are getting the key analysis step. Using warbleR, an spectrographic cross-correlation (SPCC) can be performed to find acoustic similarities in the spectrograms created. 

```{r message = FALSE, warning = FALSE}

glimpse(GroupMembership_sel_tbl)

xc_mat <- warbleR::cross_correlation(GroupMembership_sel_tbl, wl = 512, ovlp = 90, bp = c(0, 20), wn = "hanning", cor.method = "pearson", parallel = 1, na.rm = FALSE, type = "spectrogram", path = audio_path)

str(xc_mat)
dim(xc_mat)

# xc_mat[1:5, 16:24]

xc_mat[xc_mat < 0]

# Get the percentage of values that are negative
neg_values <- length(xc_mat[xc_mat<0])/(dim(xc_mat)[1]*dim(xc_mat)[2])

# Stop the function if the percentage of negative values is > 0%
if(neg_values > 0){
  stop("Negative values are present in the spectrographic cross-correlation matrix")
}

xc_mat[xc_mat < 0]

# Update the dimension names of the matrix
dimnames(xc_mat) <- list(GroupMembership_sel_tbl$sound.files, GroupMembership_sel_tbl$sound.files)

```

This will output data about the measured acoustic similarities of all the vocalizations in the dataset using the previously created spectrograms using warbleR.

<u> Step 4: Create acoustic space plots for the vocalizations </u>

Using the results from the SPCC, acoustic space plots can be used as a figure to represent the acoustic similarity of all the calls in the dataset. 

```{r message = FALSE, warning = FALSE}

# View(xc_mat)

# Convert to a distance matrix and dist object for isoMDS
dist_mat <- stats::as.dist(1 - xc_mat, diag = TRUE, upper = TRUE)
# str(dist_mat)

iso <- invisible(MASS::isoMDS(dist_mat, k = 2, maxit = 1000, trace = FALSE))
str(iso)

mds_df <- data.frame(
  sound.files = dimnames(xc_mat)[[1]],
  X = as.vector(iso$points[, 1]), 
  Y = as.vector(iso$points[, 2])
) %>% 
  inner_join(
    GroupMembership_sel_tbl %>% 
      dplyr::select(sound.files, group_ID, individual_ID),
    by = c("sound.files")
  ) %>% 
  # glimpse()
  dplyr::mutate(
    group_ID = paste("group", group_ID, sep = "_"),
    individual_ID = paste("individual", individual_ID, sep = "_"),
    unique_individuals = paste(group_ID, individual_ID, sep = " - "),
    group_ID = factor(group_ID),
    individual_ID = factor(individual_ID),
    unique_individuals = factor(unique_individuals)
  )

glimpse(mds_df)
# View(mds_df)

levels(mds_df$group_ID)
levels(mds_df$individual_ID)
levels(mds_df$unique_individuals)

# Colors by group
cols <- scales::alpha(c("navy", "orange", "forestgreen", "firebrick", "grey"), 0.65)

# Shapes by individual within groups
shps <- rep(c(21, 23, 24, 6), length(levels(mds_df$group_ID)))

# Convex hull polygons per group or unique individual
# hulls <- plyr::ddply(mds_df, "unique_individuals", function(x){
#   x[chull(x$X, x$Y), ]
# })

hulls <- plyr::ddply(mds_df, "group_ID", function(x){
  x[chull(x$X, x$Y), ]
})

glimpse(hulls)

mds_df %>%
  ggplot(aes(x = X, y = Y, color = group_ID)) + 
  geom_polygon(data = hulls, aes(x = X, y = Y, fill = group_ID, color = group_ID), alpha = 0.2, size = 0.2, show.legend = FALSE) +
  geom_point(aes(fill = group_ID, color = group_ID, shape = individual_ID), size = 2, stroke = 0.5) +
  scale_shape_manual(values = shps) +
  scale_color_manual(values = cols) +
  scale_fill_manual(values = cols) +
  xlab("") + ylab("") + 
  guides(color = "none", shape = "none", fill = "none") +
  theme_bw() +
  theme(
    axis.title = element_text(size = 14),
    axis.text = element_text(size = 9),
    strip.text.x = element_text(size = 12),
    strip.text.y = element_text(size = 10),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    axis.ticks = element_line(size = 0.25),
    plot.margin = margin(0, 3, -3, -3)
  )

```

This will output acoustic space plots to represent the acoustic similarity of the paRsynth generated vocalizations using the spectrograms created in vignette 02 for the first data set that has more group information. 

**2nd Example - Individual Information > Group Information**

Now lets run this code to analyze the bioacoustic similarities for the 2nd example dataset with more individual information than group information.

```{r eval = TRUE}

IndividualIdentity_sel_tbl <- sel_tbl %>%
    dplyr::filter(grepl("IndividualIdentity", sound.files))

warbleR::spectrograms(IndividualIdentity_sel_tbl, wl = 512, flim = c(0, 12), wn = "hanning", pal = reverse.gray.colors.2,ovlp = 90, inner.mar = c(5, 4, 4, 2), outer.mar = c(0, 0, 0, 0), picsize = 1, res = 100, cexlab = 1, propwidth = FALSE, xl = 1, osci = FALSE, gr = FALSE, sc = FALSE, line = FALSE, mar = 0.05, it = "jpeg", parallel = 1, path = audio_path, pb = TRUE, fast.spec = FALSE, by.song = NULL, sel.labels = NULL, title.labels = NULL, dest.path = images_path, box = TRUE, axis = TRUE)

# Rename the image files
imgs <- list.files(images_path)
imgs

new_nms <- gsub(".wav-1", "", imgs)
new_nms

invisible(file.rename(file.path(images_path, imgs), file.path(images_path, new_nms)))

xc_mat2 <- warbleR::cross_correlation(IndividualIdentity_sel_tbl, wl = 512, ovlp = 90, bp = c(0, 20), wn = "hanning", cor.method = "pearson", parallel = 1, na.rm = FALSE, type = "spectrogram", path = audio_path)

str(xc_mat2)
dim(xc_mat2)

# xc_mat[1:5, 16:24]

xc_mat2[xc_mat2 < 0]

# Get the percentage of values that are negative
neg_values2 <- length(xc_mat2[xc_mat2<0])/(dim(xc_mat2)[1]*dim(xc_mat2)[2])

# Stop the function if the percentage of negative values is > 0%
if(neg_values2 > 0){
  stop("Negative values are present in the spectrographic cross-correlation matrix")
}

xc_mat2[xc_mat2 < 0]

# Update the dimension names of the matrix
dimnames(xc_mat2) <- list(IndividualIdentity_sel_tbl$sound.files, IndividualIdentity_sel_tbl$sound.files)

# View(xc_mat2)

# Convert to a distance matrix and dist object for isoMDS
dist_mat2 <- stats::as.dist(1 - xc_mat2, diag = TRUE, upper = TRUE)
# str(dist_mat)

iso2 <- invisible(MASS::isoMDS(dist_mat2, k = 2, maxit = 1000, trace = FALSE))
str(iso2)

mds_df2 <- data.frame(
  sound.files = dimnames(xc_mat2)[[1]],
  X = as.vector(iso2$points[, 1]), 
  Y = as.vector(iso2$points[, 2])
) %>% 
  inner_join(
    IndividualIdentity_sel_tbl %>% 
      dplyr::select(sound.files, group_ID, individual_ID),
    by = c("sound.files")
  ) %>% 
  # glimpse()
  dplyr::mutate(
    group_ID = paste("group", group_ID, sep = "_"),
    individual_ID = paste("individual", individual_ID, sep = "_"),
    unique_individuals = paste(group_ID, individual_ID, sep = " - "),
    group_ID = factor(group_ID),
    individual_ID = factor(individual_ID),
    unique_individuals = factor(unique_individuals)
  )

glimpse(mds_df2)
# View(mds_df)

levels(mds_df2$group_ID)
levels(mds_df2$individual_ID)
levels(mds_df2$unique_individuals)

# Colors by group
cols <- scales::alpha(c("navy", "orange", "forestgreen", "firebrick", "grey"), 0.65)

# Shapes by individual within groups
shps <- rep(c(21, 23, 24, 6), length(levels(mds_df2$group_ID)))

# Convex hull polygons per group or unique individual
# hulls <- plyr::ddply(mds_df, "unique_individuals", function(x){
#   x[chull(x$X, x$Y), ]
# })

hulls2 <- plyr::ddply(mds_df2, "group_ID", function(x){
  x[chull(x$X, x$Y), ]
})

glimpse(hulls2)

mds_df2 %>%
  ggplot(aes(x = X, y = Y, color = group_ID)) + 
  geom_polygon(data = hulls2, aes(x = X, y = Y, fill = group_ID, color = group_ID), alpha = 0.2, size = 0.2, show.legend = FALSE) +
  geom_point(aes(fill = group_ID, color = group_ID, shape = individual_ID), size = 2, stroke = 0.5) +
  scale_shape_manual(values = shps) +
  scale_color_manual(values = cols) +
  scale_fill_manual(values = cols) +
  xlab("") + ylab("") + 
  guides(color = "none", shape = "none", fill = "none") +
  theme_bw() +
  theme(
    axis.title = element_text(size = 14),
    axis.text = element_text(size = 9),
    strip.text.x = element_text(size = 12),
    strip.text.y = element_text(size = 10),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    axis.ticks = element_line(size = 0.25),
    plot.margin = margin(0, 3, -3, -3)
  )

```

This will output acoustic space plots to represent the acoustic similarity of the paRsynth generated vocalizations using the spectrograms created in vignette 02 for the second data set that has more individual information. 

This last vignette has showed you how to conduct downstream bioacoustic analysis on two datasets: 1) more group information and 2) more individual information and create acoustic space plots for them. You completed the final vignette of the paRsynth package, well done!
