---
title: "Vignette_03_Analysis"
author: "GAJ"
date: "2024-12-11"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
<h2>How to Use paRsynth Functions</h2>

In this vignette, we will go through how to use the synthetic vocalization generated by the paRsynth package for downstream bioacoustics analysis. 

<u> Step 1: Save the metadata for the synthetic audio files to a CSV file </u>

```{r}

# Add extra metadata for upcoming image files names and rearrange columns
synthetic_call_metadata %>%
  write.csv(., file = file.path(analysis_path, "synthetic_call_metadata.csv"), row.names = FALSE) 

```

<u> Step 2: Create a warbleR selection table </u>

```{r}
# Create a vector of all the audio files in the analysis path
wavs <- list.files(path = audio_path, pattern = ".wav$", full.names = FALSE)
length(wavs)
head(wavs)

# w <- 1 # testing

sel_tbl <- data.table::rbindlist(lapply(1:length(wavs), function(w){
  
  tmp <- tuneR::readWave(file.path(audio_path, wavs[w]))

  # Return the metadata for the given call using the synthetic metadata generated during audio file generation above
  metadats_tmp <- synthetic_call_metadata %>%
    dplyr::filter(grepl(wavs[w], audio_file_name))
  
  # glimpse(metadats_tmp)
  
  # Create a row for the selection table in warbleR format if the audio file exists and metadata for that file also exists
  if(nrow(metadats_tmp) > 0){
    
    # Use 0.1s as a margin to indicate where the vocalization starts and ends in the audio file
    # soundgen::soundgen() adds 100ms of silence before and after the synthetic vocalization by default 
    res <- data.frame(
      sound.files = wavs[w], 
      selec = 1,
      start = 0.1, 
      end = seewave::duration(tmp) - 0.1,
      sampling_rate = tmp@samp.rate,
      group_ID = metadats_tmp[["Group"]],
      individual_ID = metadats_tmp[["Individual"]],
      call_ID = metadats_tmp[["Call"]]
    )
    
  } else {
    
    res <- data.frame(
      sound.files = wavs[w], 
      selec = 1, 
      start = 0.1, 
      end = seewave::duration(tmp) + 0.1,
      sampling_rate = NA,
      group_ID = NA,
      individual_ID = NA,
      call_ID = NA
    )
    
  }
  
  return(res)
  
}))

# See the selection table in warbleR format with all useful metadata for the synthetic experiment
glimpse(sel_tbl)

unique(sel_tbl$sampling_rate)

```

<u> Step 3: Create spectrogram image files of each audio file </u>

```{r}

warbleR::spectrograms(sel_tbl, wl = 512, flim = c(0, 12), wn = "hanning", pal = reverse.gray.colors.2,ovlp = 90, inner.mar = c(5, 4, 4, 2), outer.mar = c(0, 0, 0, 0), picsize = 1, res = 100, cexlab = 1, propwidth = FALSE, xl = 1, osci = FALSE, gr = FALSE, sc = FALSE, line = FALSE, mar = 0.05, it = "jpeg", parallel = 1, path = audio_path, pb = TRUE, fast.spec = FALSE, by.song = NULL, sel.labels = NULL, title.labels = NULL, dest.path = images_path, box = TRUE, axis = TRUE)

# Rename the image files
imgs <- list.files(images_path)
imgs

new_nms <- gsub(".wav-1", "", imgs)
new_nms

invisible(file.rename(file.path(images_path, imgs), file.path(images_path, new_nms)))

```

<u> Step 4. Perform spectrogrphic cross-correlation (SPCC) to measure acoustic similarity of all calls in dataset (pairwise similarity matrix) </u>

```{r}

glimpse(sel_tbl)

xc_mat <- warbleR::cross_correlation(sel_tbl, wl = 512, ovlp = 90, bp = c(0, 20), wn = "hanning", cor.method = "pearson", parallel = 1, na.rm = FALSE, type = "spectrogram", path = audio_path)

str(xc_mat)
dim(xc_mat)

# xc_mat[1:5, 16:24]

xc_mat[xc_mat < 0]

# Get the percentage of values that are negative
neg_values <- length(xc_mat[xc_mat<0])/(dim(xc_mat)[1]*dim(xc_mat)[2])

# Stop the function if the percentage of negative values is > 0%
if(neg_values > 0){
  stop("Negative values are present in the spectrographic cross-correlation matrix")
}

xc_mat[xc_mat < 0]

# Update the dimension names of the matrix
dimnames(xc_mat) <- list(sel_tbl$sound.files, sel_tbl$sound.files)

```

<u> Step 5. Create acoustic space plots for the vocalizations </u>

```{r}

# View(xc_mat)

# Convert to a distance matrix and dist object for isoMDS
dist_mat <- stats::as.dist(1 - xc_mat, diag = TRUE, upper = TRUE)
# str(dist_mat)

iso <- invisible(MASS::isoMDS(dist_mat, k = 2, maxit = 1000, trace = FALSE))
str(iso)

mds_df <- data.frame(
  sound.files = dimnames(xc_mat)[[1]],
  X = as.vector(iso$points[, 1]), 
  Y = as.vector(iso$points[, 2])
) %>% 
  inner_join(
    sel_tbl %>% 
      dplyr::select(sound.files, group_ID, individual_ID),
    by = c("sound.files")
  ) %>% 
  dplyr::mutate(
    group_ID = paste("group", group_ID, sep = "_"),
    individual_ID = paste("individual", individual_ID, sep = "_"),
    unique_individuals = paste(group_ID, individual_ID, sep = " - "),
    group_ID = factor(group_ID),
    individual_ID = factor(individual_ID),
    unique_individuals = factor(unique_individuals)
  )

glimpse(mds_df)
# View(mds_df)

levels(mds_df$group_ID)
levels(mds_df$individual_ID)
levels(mds_df$unique_individuals)

# Colors by group
cols <- scales::alpha(c("navy", "orange", "forestgreen", "firebrick", "grey"), 0.65)

# Shapes by individual within groups
shps <- rep(c(21, 23, 24, 6), length(levels(mds_df$group_ID)))

# Convex hull polygons per group or unique individual
# hulls <- plyr::ddply(mds_df, "unique_individuals", function(x){
#   x[chull(x$X, x$Y), ]
# })

hulls <- plyr::ddply(mds_df, "group_ID", function(x){
  x[chull(x$X, x$Y), ]
})

glimpse(hulls)

mds_df %>%
  ggplot(aes(x = X, y = Y, color = group_ID)) + 
  geom_polygon(data = hulls, aes(x = X, y = Y, fill = group_ID, color = group_ID), alpha = 0.2, size = 0.2, show.legend = FALSE) +
  geom_point(aes(fill = group_ID, color = group_ID, shape = individual_ID), size = 2, stroke = 0.5) +
  scale_shape_manual(values = shps) +
  scale_color_manual(values = cols) +
  scale_fill_manual(values = cols) +
  xlab("") + ylab("") + 
  guides(color = "none", shape = "none", fill = "none") +
  theme_bw() +
  theme(
    axis.title = element_text(size = 14),
    axis.text = element_text(size = 9),
    strip.text.x = element_text(size = 12),
    strip.text.y = element_text(size = 10),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    axis.ticks = element_line(size = 0.25),
    plot.margin = margin(0, 3, -3, -3)
  )

```

Run the same steps above, but instead create a data set of synthetic vocalizations with more individual information than group information (This will require changes to the arguments in generate_strings(), as well as the prefix used in write_audio().)

Compare what your did with our results with individual information = TKTK and group information = TKTK. 

TKTK Placeholder TKTK
<br>
![paRsynth graphic workflow](~/Desktop/BIRDS/WorkflowGraphics/paRsynthMethods/paRsynth_methods_workflow.svg)
